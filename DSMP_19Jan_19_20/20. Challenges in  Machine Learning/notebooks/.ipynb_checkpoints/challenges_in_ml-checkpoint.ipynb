{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# To print multiple outputs together\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Change column display number during print\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Challenges in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda:\n",
    "***\n",
    "* What is Imbalanced Data\n",
    "* Dealing with imbalanced data\n",
    "    * Evaluation Metrics\n",
    "    * Resampling Techniques\n",
    "    * Algorithmic Techniques\n",
    "* Dealing with small datasets\n",
    "* Values of K in K-Fold validation\n",
    "* Do we need hundreds of classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## John and Lucius again\n",
    "***\n",
    "John and Lucius were finally out, in a nice looking pub, having drinks that were promised but never delivered to them. Having studied about all the cool algorithms, John was now pondering upon his journey. No amount of machine learning would have been able to predict his journey from house hunting to learning about ML algorithms. At least that's what he believed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## John and Lucius again\n",
    "***\n",
    "John, now seriously considering a career in ML and data science started thinking about all the practical challenges ML professionals would come across. One of the first ones that came to his mind was: \"What if the classes in a classification problem were really skewed towards one of the classes?\" He told about this to Lucius. Lucius wanted to enjoy his drinks for once, but looking at John's enthusiasm, he realized that he had no choice. \"Imbalanced Datasets\", he muttered reluctantly and started explaining:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Imbalanced Data\n",
    "***\n",
    "\n",
    "* Imbalanced Data is a slightly inaccurate term we use to describe datasets where the distribution of the target variable is imbalanced.\n",
    "* This is most visible and easily detected for binary classification tasks, where most of the instances (data points) belong to one of the classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg of imbalance dataset --> classification task\n",
    "Yes = 99 (not spam)\n",
    "No = 1 (spam)\n",
    "\n",
    "Fraud\n",
    "Raining in summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Imbalanced Data\n",
    "***\n",
    "* Class-imbalance regularly occurs in datasets pertaining to multi-class classification tasks as well.\n",
    "* Detecting it in Regression tasks can take a little more effort, and plotting a histogram of the target variable is a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Examples\n",
    "***\n",
    "Imbalanced datasets frequently occur in\n",
    "\n",
    "* Anomaly detection\n",
    "    * Electricity pilferage\n",
    "    * Fraudulent transactions in banks\n",
    "* Predicting Rare events\n",
    "    * Ad click-through-rate (CTR) prediction (~1%)\n",
    "    * Identification of rare diseases\n",
    "    * User Churn (for example, usera churn is ~2% in telecom industry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "123 - Not Fraud\n",
    "123 - Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Understanding Imbalanced Data\n",
    "***\n",
    "Let's look at detection of credit card fraud to understand this in more detail, said Lucius recalling his encounter with such a problem.\n",
    "\n",
    "* Credit card fraud is a widespread problem and accounts for millions of dollars in loss.\n",
    "* But, given the extremely high number of credit card transactions everyday, fraudulent transactions represent only a small fraction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Even then, fraudulent transactions have an outsized impact on the revenue, because\n",
    "* Almost the entire value of a fraudulent transaction counts towards loss (less insurance), whereas\n",
    "* The profit from a genuine transaction is a fraction of the total transaction value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Thus it's more important to recall fraudulent transactions, even if that means we'll end up labeling some genuine transactions as fraud \n",
    "* This is more of a business call, actually, depending on a wide range of factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Type 1 and Type 2\n",
    "H0 = Not fraud\n",
    "Ha = Fraud\n",
    "\n",
    "Type1 - Fraud when it was not a fraud - false alarm ! you may ending calling customer to confirm\n",
    "Type2 - Not fraud when it was actually fraud \n",
    "\n",
    "alpha = 0.01 (you need a very strong evidence for you to conclude fraud)\n",
    "alpha = 0.05\n",
    "alpha = 0.1 (you may not need a very strong evidence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Even though the typical datasets recording credit card transaction are very large (millions of row), the number of fraudulent records tends to be a very small fraction of the datasets - around 1% to 2%.\n",
    "* Thus, if a given dataset of credit card transactions has a million row, only about 10,000 of them will be from fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No - 1000000\n",
    "Yes - 10000\n",
    "\n",
    "any pattern which was present from 10k gets overshadowed by the majority class\n",
    "model ends up learning patterns only from dominant class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "95 - blue\n",
    "5 - light blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So what? blurted John, I can still train a model and try and predict if a transaction in fraudulent or not. Yes, you can, but that is likely to give you not-so-good results, said Lucius. Let me explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Consequences of imbalanced classes:\n",
    "***\n",
    "**Bias in the model towards dominant class**\n",
    "\n",
    "* Most machine learning models will end up predicting most of the transactions as genuine as they end up learning from mostly positive instances.\n",
    "* Accounting for this in the way the model sees the data (resampling strategies) or the way it learns (error metric, algorithmic tweaks) can help us build models that are better at predicting the minor class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Consequences of imbalanced classes:\n",
    "***\n",
    "**Difficulty in assessing model performance**\n",
    "\n",
    "* For the credit card dataset discussed before, if we classify all transactions as genuine, we might still have an accuracy of 99%! (Bias towards dominant class)\n",
    "* Let's look at a problem we are more likely to encounter in practice. \n",
    "* Suppose we have built two models, A and B, to predict fraudulent transactions, and we want to select the one with better performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Consequences of imbalanced classes:\n",
    "***\n",
    "**Model A**\n",
    "\n",
    "* Of the 99% genuine transactions, this model predicts 98.5% correctly\n",
    "* Of the 1% fraudulent transactions, this model predicts 0.25% correctly\n",
    "\n",
    "**Model accuracy: 98.75%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Consequences of imbalanced classes:\n",
    "***\n",
    "**Model B**\n",
    "* Of the 99% genuine transactions, this model predicts 98.25% correctly\n",
    "* Of the 1% fraudulent transactions, this model predicts 0.5% correctly\n",
    "\n",
    "**Model accuracy: 98.75%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Consequences of imbalanced classes:\n",
    "***\n",
    "* **Which of these two models performs better?**\n",
    "* **Which one of these two should we use?**\n",
    "\n",
    "\n",
    "* Clearly Model B is more valuable to us, but Accuracy, one of the most common metrics used in classification, fails to reflect that.\n",
    "* We need to use a metric that not only captures the class imbalance better, but one that also lets us make meaningful trade-offs between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"Hmmm... Interesting...\" said John, scratching head, \"So how do we deal with such a dataset?\"\n",
    "\n",
    "Lucius tried to recall a few techniques he studied in college. After some time he started:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Dealing with Imbalanced Data\n",
    "***\n",
    "Here are the ways to handle the imbalanced data\n",
    "\n",
    "* More suited error metrics (comparatively immune to class imbalance)\n",
    "* Resampling strategies\n",
    "* Algorithmic techniques\n",
    "* Buy/Collect more data - wait for more fraud txns/wait for more ppl to fall sick\n",
    "\n",
    "Let's look at them one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More Appropriate Error Metrics\n",
    "***\n",
    "The idea is to choose an error metric that is immune to class imbalance. As we saw earlier, accuracy is something that is not very robust against class imbalance. Following are a few examples of such error metrics\n",
    "\n",
    "1. Confusion Matrix\n",
    "2. Precision / Recall / Sensitivity / Specificity\n",
    "3. AUC ROC - PR AUC\n",
    "4. f1 Score\n",
    "5. Cohen's Kappa\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have already gone through all the metrics, except Cohen's kappa. So let's understand Cohen's kappa better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cohen’s Kappa \n",
    "How good your classifier power is in comparison to random classifier\n",
    "\n",
    "100 records\n",
    "2 ways to classifiy \n",
    "1. learn the pattern and then classify\n",
    "2. randomly classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Cohen’s Kappa:\n",
    "***\n",
    "* The Kappa statistic (or value) is a metric that compares an Observed Accuracy (your classifier) with an Expected Accuracy (random chance). \n",
    "* Let's understand how Cohen's kappa is defined using a confusion matrix\n",
    "![](../images/image20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Here, let's say rows (A) are the predicted values and columns (B) are the actual values.\n",
    "* Now let's understand observed accuracy and expected accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Observed Accuracy is simply the number of instances that were classified correctly throughout the entire confusion matrix.\n",
    "\n",
    "![](../images/image20.png)\n",
    "![](../images/image19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Expected Accuracy is defined as the accuracy that any classifier would be expected to achieve by random chance.\n",
    "\n",
    "Sounds confusing? Let's break this down.\n",
    "\n",
    "Our classifier classifies \n",
    "* (a + b) observations as yes\n",
    "* (c + d) observations as no\n",
    "\n",
    "\n",
    "* Hence, the probability of a randomly chosen observation being classified as yes is (P1): (a + b) / (a + b + c + d)\n",
    "* And, the probability of a randomly chosen observation being classified as no is (P2): (c + d) / (a + b + c + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Reality:\n",
    "* (a + c) observations as yes\n",
    "* (b + d) observations as no\n",
    "\n",
    "\n",
    "* Hence, the probability of a randomly chosen observation being classified as yes is (P3): (a + c) / (a + b + c + d)\n",
    "* And, the probability of a randomly chosen observation being classified as no is (P4): (b + d) / (a + b + c + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 (Your classifier) = Prob of saying Yes\n",
    "P2 (Your classifier) = Prob of saying No\n",
    "\n",
    "P3 (Truth) = Prob of saying Yes\n",
    "P4 (Truth) = Prob of saying No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Probability of a randomly chosen sample being *CORRECTLY* classified is \n",
    "\n",
    "* when the classifier classifies it as yes AND it is in reality yes: P1*P3\n",
    "* when the classifier classifies it as no AND it is in reality no: P2*P4\n",
    "\n",
    "Hence, Expected probability of a randomly chosen sample being *CORRECTLY* classified is: P1 x P3 + P2 x P4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](../images/image20.png)\n",
    "![](../images/image23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](../images/image20.png)\n",
    "![](../images/image23.png)\n",
    "![](../images/image22.png)\n",
    "![](../images/image21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Great! now that we understand $P_o$ and $P_e$, Cohen's kappa is defined as\n",
    "\n",
    "![](../images/image24.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal = 1\n",
    "as high as possible\n",
    "how much of impact your business can take\n",
    "10 fraud - 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* In essence, the kappa statistic is a measure of how closely the instances classified by the machine learning classifier matched the data labeled as ground truth, controlling for the accuracy of a random classifier as measured by the expected accuracy. \n",
    "* Not only can this kappa statistic shed light into how the classifier itself performed, the kappa statistic for one model is directly comparable to the kappa statistic for any other model used for the same classification task.\n",
    "* For any arbitrary accuracy value, more the Kappa value, better the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Q: Here is an example of 2 classifiers with given confusion matrix. Which one do you think is performing better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Classifier A**\n",
    "\n",
    "![](../images/image25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**CLassifier B**\n",
    "\n",
    "![](../images/image27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A: It is apparent that for given accuracy, classifier A is doing a much better job at classifying than classifier B, which is also reflected in higher Kappa value attained by classifier A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"Wow! that is an interesting metric to use!\" said John. What else we can do? Lucius again went searching the attics of his mind, looking for some other techniques he had studies. And started recalling the resampling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Resampling Techniques\n",
    "***\n",
    "\n",
    "Resampling methods are techniques in which , we try to **reduce the proportion of the dominant class by undersampling** from it, or we try to **increase the proportion of the minor class by oversampling** from it.\n",
    "However, some of the more successful approaches combine both oversampling and undersampling.\n",
    "\n",
    "Let's have a look at them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Undersampling:\n",
    "***\n",
    "Undersampling techniques try to balance out the classes by reducing the number of observations in the dominant classes. \n",
    "\n",
    "![](../images/image26.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple random sample\n",
    "Cons of using undersampling\n",
    "1. throwing away data/ loss of data\n",
    "2. underfitting\n",
    "3. there can be multiple patterns in majority itself, which you might miss\n",
    "\n",
    "Undersampling\n",
    "1. Where lots of millions and millions of records\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Undersampling\n",
    "***\n",
    "There are many undersampling techniques. Let's look at some of them.\n",
    "\n",
    "* Random Undersampling\n",
    "* Cluster Centroids\n",
    "* Tomek Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Undersampling - Random Undersampling\n",
    "***\n",
    "Random undersampling is one of the most intuitive and naive methods for undersampling. This method works by randomly choosing the samples from dominant classes. Let's understand the random undersampling by a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example 1**\n",
    "* Total number of observations: 1000\n",
    "* Total number of classes: 2 (A, B)\n",
    "* Size of class A: 975\n",
    "* Size of class B: 25\n",
    "* Proportion of Minor class: 2.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sampled Dataset**\n",
    "* From A, select 25 points randomly\n",
    "* From B, select all 25 points\n",
    "* Proportion of Minor class: 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example 2**\n",
    "* Total number of observations: 1000\n",
    "* Total number of classes: 3 (A, B, C)\n",
    "* Size of class A: 925\n",
    "* Size of class B: 25\n",
    "* Size of class C: 50\n",
    "* Proportion of Minor classes: 2.5% (B) and 5% (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sampled Dataset**\n",
    "* From A, select 425 points randomly\n",
    "* From B, select all 25 points\n",
    "* From C, select all 50 points\n",
    "* Proportion of Minor class: 5% (B) and 10% (C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loan_predition = pd.read_csv(\"../data/loan_prediction.csv\", )\n",
    "loan_predition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "for column in loan_predition.select_dtypes(include=[\"object\"]).columns.values:\n",
    "    loan_predition[column] = label_enc.fit_transform(loan_predition[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_predition.Loan_Status.value_counts()\n",
    "loan_predition.Loan_Status.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "422/192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.countplot(loan_predition.Loan_Status);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I am calling my minority class as 1\n",
    "I am calling my majority class as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loan_predition.replace({0:1, 1:0}, inplace=True)\n",
    "# index_values = loan_predition[loan_predition.Loan_Status == 1][100:].index.values\n",
    "# loan_predition = loan_predition.drop(loan_predition.index[list(index_values)])\n",
    "sns.countplot(loan_predition.Loan_Status);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(loan_predition.iloc[:,:-1], \n",
    "                                                    loan_predition.iloc[:,-1], \n",
    "                                                    random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "319/141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=9)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"f1_score\", f1_score(y_test, rf.predict(X_test)))\n",
    "print(\"precision_score\", precision_score(y_test, rf.predict(X_test)))\n",
    "print(\"recall\", recall_score(y_test, rf.predict(X_test)))\n",
    "print(\"auc\", roc_auc_score(y_test, rf.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Has less coverage but precisely saying yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=9)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"f1_score\", f1_score(y_test, lr.predict(X_test)))\n",
    "print(precision_score(y_test, lr.predict(X_test)))\n",
    "print(recall_score(y_test, lr.predict(X_test)))\n",
    "print(roc_auc_score(y_test, lr.predict(X_test)))\n",
    "print(confusion_matrix(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Undersampling with `imblearn`:\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training will happen on balance dataset ()\n",
    "however your testing will still happen on imbalance data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Create the samplers\n",
    "rus = RandomUnderSampler(random_state=9)\n",
    "X_sample2, y_sample2 =  rus.fit_sample(X_train, y_train)\n",
    "y_sample2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_sample2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(random_state=9)\n",
    "rf2.fit(X_sample2, y_sample2)\n",
    "print(\"f1_score\", f1_score(y_test, rf2.predict(X_test)))\n",
    "print(precision_score(y_test, rf2.predict(X_test)))\n",
    "print(recall_score(y_test, rf2.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf2.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf2 = LogisticRegression(random_state=9)\n",
    "rf2.fit(X_sample2, y_sample2)\n",
    "print(\"f1_score\", f1_score(y_test, rf2.predict(X_test)))\n",
    "print(precision_score(y_test, rf2.predict(X_test)))\n",
    "print(recall_score(y_test, rf2.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf2.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Undersampling - Cluster Centroids\n",
    "***\n",
    "* This technique undersampled by creation of new samples. \n",
    "* Let’s understand how\n",
    "    * Size of minority class: 200\n",
    "    * Size of majority class: 1000\n",
    "* Cluster centroids method works by creating 200 clusters of the majority class and returns the centroids of each of the clusters. Hence, rather than sampling from the original data points we get new representative sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000 --> 200\n",
    "RS --> sampling\n",
    "\n",
    "centroid\n",
    "clustering on 1000 records with K = 200\n",
    "200 centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc = ClusterCentroids(random_state=9)\n",
    "X_sample3, y_sample3 = cc.fit_sample(X_train, y_train)\n",
    "y_sample3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(random_state=9)\n",
    "rf3.fit(X_sample3, y_sample3)\n",
    "print(\"f1_score\", f1_score(y_test, rf3.predict(X_test)))\n",
    "print(precision_score(y_test, rf3.predict(X_test)))\n",
    "print(recall_score(y_test, rf3.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf3.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf3 = LogisticRegression(random_state=9)\n",
    "rf3.fit(X_sample3, y_sample3)\n",
    "print(\"f1_score\", f1_score(y_test, rf3.predict(X_test)))\n",
    "print(precision_score(y_test, rf3.predict(X_test)))\n",
    "print(recall_score(y_test, rf3.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf3.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf3.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Undersampling - Tomek Links\n",
    "***\n",
    "* Tomek Links are pairs of instances of opposite classes who are their own nearest neighbors.\n",
    "* This technique identifies Tomek Links and gets rid of the majority samples.\n",
    "* The idea is to clarify the border between the minority and majority classes, making the minority region(s) more distinct. \n",
    "\n",
    "![](../images/image31.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tl = TomekLinks(sampling_strategy='not minority')\n",
    "X_sample4, y_sample4 = tl.fit_sample(X_train, y_train)\n",
    "sns.countplot(y_sample4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf4 = RandomForestClassifier()\n",
    "rf4.fit(X_sample4, y_sample4)\n",
    "print(\"f1_score\", f1_score(y_test, rf4.predict(X_test)))\n",
    "print(precision_score(y_test, rf4.predict(X_test)))\n",
    "print(recall_score(y_test, rf4.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf4.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf4 = LogisticRegression()\n",
    "rf4.fit(X_sample4, y_sample4)\n",
    "print(\"f1_score\", f1_score(y_test, rf4.predict(X_test)))\n",
    "print(precision_score(y_test, rf4.predict(X_test)))\n",
    "print(recall_score(y_test, rf4.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf4.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Oversampling:\n",
    "***\n",
    "As opposed to undersamping, oversampling techniques try to make the classes balanced by enhancing the minority class using different techniques.\n",
    "\n",
    "![](../images/image29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Oversampling - Random Oversampling\n",
    "***\n",
    "Random oversampling selects the samples with replacement from the minority class.\n",
    "\n",
    "**Example 1**\n",
    "\n",
    "* Total number of observations: 1000\n",
    "* Total number of classes: 2 (A, B)\n",
    "* Size of class A: 975\n",
    "* Size of class B: 25\n",
    "* Proportion of Minor class: 2.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Sampled Dataset\n",
    "* From A, select all 975 points\n",
    "* From B, select 225 points with replacement\n",
    "* Proportion of Minor class: 18.75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example 2**\n",
    "\n",
    "* Total number of observations: 1000\n",
    "* Total number of classes: 3 (A, B, C)\n",
    "* Size of class A: 925\n",
    "* Size of class B: 25\n",
    "* Size of class C: 50\n",
    "* Proportion of Minor classes: 2.5% (B) and 5% (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sampled Dataset**\n",
    "* From A, select all 925 points\n",
    "* From B, select 225 points with replacement\n",
    "* From C, select 450 points with replacement\n",
    "* Proportion of Minor class: ~14% (B) and ~28% (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=9)\n",
    "X_sample5, y_sample5 = ros.fit_sample(X_train, y_train)\n",
    "y_sample5.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(y_sample5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf5 = RandomForestClassifier(random_state=9)\n",
    "rf5.fit(X_sample5, y_sample5)\n",
    "print(\"f1_score\", f1_score(y_test, rf5.predict(X_test)))\n",
    "print(precision_score(y_test, rf5.predict(X_test)))\n",
    "print(recall_score(y_test, rf5.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf5.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf5 = LogisticRegression(random_state=9)\n",
    "rf5.fit(X_sample5, y_sample5)\n",
    "print(\"f1_score\", f1_score(y_test, rf5.predict(X_test)))\n",
    "print(precision_score(y_test, rf5.predict(X_test)))\n",
    "print(recall_score(y_test, rf5.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf5.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf5.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Oversampling - SMOTE (Synthetic Minority Oversampling Technique)\n",
    "***\n",
    "* The original paper: [SMOTE: Synthetic Minority Over-sampling Technique](https://arxiv.org/pdf/1106.1813.pdf)\n",
    "* The minority class is over-sampled by creating synthetic examples rather than by over-sampling with replacement.\n",
    "* It generates synthetic examples in a less application-specific manner, by operating in feature space rather than data space.\n",
    "* The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the k minority class nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 records of majority\n",
    "1 record of minority"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## How SMOTE works:\n",
    "***\n",
    "* Take the difference between the feature vector (sample) under consideration and its nearest neighbor.\n",
    "* Multiply this difference by a random number between 0 and 1, and add it to the feature vector under consideration.\n",
    "* This causes the selection of a random point along the line segment between two specific features.\n",
    "![](../images/image32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Depending upon the amount of over-sampling required, neighbors from the k nearest neighbors are randomly chosen.\n",
    "* For instance, if the amount of over-sampling needed is 200%, only two neighbors from the five nearest neighbors are chosen and one sample is generated in the direction of each.\n",
    "* NOTE: this k becomes a hyperparameter for SMOTE algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Limitation: Because it operates by interpolating between rare examples.\n",
    "* Hence, it can only generate examples within the body of available examples—never outside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "smote = BorderlineSMOTE(random_state=9, kind=\"borderline-2\")\n",
    "X_sample6, y_sample6 = smote.fit_sample(X_train, y_train)\n",
    "sns.countplot(y_sample6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf6 = RandomForestClassifier(random_state=9)\n",
    "rf6.fit(X_sample6, y_sample6)\n",
    "print(\"f1_score\", f1_score(y_test, rf6.predict(X_test)))\n",
    "print(precision_score(y_test, rf6.predict(X_test)))\n",
    "print(recall_score(y_test, rf6.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf6.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf6.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rf6 = LogisticRegression(random_state=9)\n",
    "rf6.fit(X_sample6, y_sample6)\n",
    "print(\"f1_score\", f1_score(y_test, rf6.predict(X_test)))\n",
    "print(precision_score(y_test, rf6.predict(X_test)))\n",
    "print(recall_score(y_test, rf6.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf6.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf6.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithmic Approach\n",
    "***\n",
    "In algorithmic approach, we use different techniques to tweak the algorithms to make them learn minority classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithmic Approach - Cost Sensitive Training (Penalised Training): \n",
    "***\n",
    "* One way to do so is to create a custom metric which penalizes wrong predictions in the minority class.\n",
    "* Recall the metric the we defined while discussing the metrics of evaluation:\n",
    "* metric=(5 ∗ false negative + 1 ∗ false positive) / 6\n",
    "* Such metrics could be used in handling the imbalanced datasets.\n",
    "* sklearn provides a method to device custom metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Technical-Stuff.png\" alt=\"Technical-Stuff\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "<br />\n",
    "\n",
    "## Algorithmic Approach - Choice of Algorithm:\n",
    "***\n",
    "* Ensemble methods, especially Random Forests are found to be good at handling imbalanced datasets\n",
    "* These methods are able to learn classes based on importance assigned to them.\n",
    "* sklearn's implementations of these algorithms provides option to handle imbalanced dataset by setting the **`class_weight`** parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 class records of 0\n",
    "1 reocrd of 1 - minority class\n",
    "2:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class_wts = range(50)\n",
    "f1s = []\n",
    "auc = []\n",
    "precs = []\n",
    "recalls = []\n",
    "\n",
    "for wt in class_wts:\n",
    "    rf7 = RandomForestClassifier(random_state=9, class_weight={0:wt,1:1})\n",
    "    rf7.fit(X_train, y_train)\n",
    "    f1s.append(f1_score(y_test, rf7.predict(X_test)))\n",
    "    precs.append(precision_score(y_test, rf7.predict(X_test)))\n",
    "    recalls.append(recall_score(y_test, rf7.predict(X_test)))\n",
    "    auc.append(roc_auc_score(y_test, rf7.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.argmax(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(auc)\n",
    "np.argmax(f1s)\n",
    "np.argmax(precs)\n",
    "np.argmax(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#max_scorer = f1s.index(np.max(f1s))\n",
    "max_scorer = precs.index(np.max(precs))\n",
    "max_scorer\n",
    "rf7 = RandomForestClassifier(random_state=9, class_weight={0:max_scorer,1:1})\n",
    "rf7.fit(X_train, y_train)\n",
    "print(\"f1_score\", f1_score(y_test, rf7.predict(X_test)))\n",
    "print(precision_score(y_test, rf7.predict(X_test)))\n",
    "print(recall_score(y_test, rf7.predict(X_test)))\n",
    "print(roc_auc_score(y_test, rf7.predict(X_test)))\n",
    "print(confusion_matrix(y_test, rf7.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8));\n",
    "plt.plot(class_wts, f1s, label=\"F1 scores\");\n",
    "plt.plot(class_wts, auc, label=\"AUC scores\");\n",
    "plt.xlabel(\"class weight\");\n",
    "plt.ylabel(\"scores\");\n",
    "plt.title(\"Effect of Class Wt. in Imbalanced Classes\");\n",
    "plt.ylim(0.45, 0.8);\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Useful tips:\n",
    "***\n",
    "* While carrying out cross-validation, make stratified folds to make sure the presence of minority class in all folds\n",
    "* Instead of predictions, get probabilities from the trained classifier.\n",
    "* Study the AUC-ROC curve and adjust the prediction threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\"Phew! that was a lot of techniques to understand in one go!\", John already looked overwhelmed. Lucius, smiling mildly, just added: \"and we just scratched the surface\". There are a lot more techniques that can be employed. It might be worth checking out `imblearn's` official documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Off to other challenges\n",
    "***\n",
    "After concluding the discussion on imbalanced datasets, John started wondering about some more problems that can come along the way. He remembered being told again and again how important the data is for any ML problem. He immediately started thinking what if there is too little data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## Dealing with Smaller Datasets:\n",
    "***\n",
    "Sometimes, challenge arises not because of too much data, but because of too less data. Such a scenario is known as  **the curse of dimensionality**, which essentially means **number of features >> number of observations**\n",
    "\n",
    "\n",
    "* In case of such small datasets, following are some of the techniques that could come in handy\n",
    "    * Exploit Bootstrapping\n",
    "    * Use Simpler, Regularized Models (definitelye yes)\n",
    "    * Use Ensemble Techniques (Not sure)\n",
    "    * Use Support Vector Machines (yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Value of K in Koolness\n",
    "***\n",
    "What is the value of k in k-fold validation that should be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimum Value of K in K-Fold Validation:\n",
    "***\n",
    "* Refresher: Why do we use cross-validation?\n",
    "* Trade-off:\n",
    "    * Higher K: More samples to train, more cross-validation, results in less bias, high variance but requires more computations\n",
    "    * Lower K: Less samples to train, less cross-validation, results in more bias, low variance but requires less computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimum Value of K in K-Fold Validation:\n",
    "***\n",
    "* According to paper [A Study of Cross Validation and Bootstrap for Accuracy Estimation and Model Selection](http://robotics.stanford.edu/~ronnyk/accEst.pdf), value of k=10 is a good balance between accuracy and training time\n",
    "* Stratified k-fold seems to perform better\n",
    "![](../images/image33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimum Value of K in K-Fold Validation:\n",
    "***\n",
    "\n",
    "* [Here](https://vinhkhuc.github.io/2015/03/01/how-many-folds-for-cross-validation.html) is a python implementation of the same experiment for iris dataset.\n",
    "* For smaller datasets, usually leave-one-out validation works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Concept-Alert.png\" alt=\"Concept-Alert\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "## The Age old Question - Which Algorithm to Use?\n",
    "***\n",
    "Having studied a bunch of algorithms is good, but choosing which one to use is not! Let's understand which algorithms perform better in which scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - A perspective from a Research Paper\n",
    "***\n",
    "In [this](http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf) paper,\n",
    "The researchers evaluated **179 classifiers** arising from **17 families**, implemented in Weka, R, C and Matlab.\n",
    "They used **121 datasets**, which represent the whole UCI database and other real problems, in order to achieve significant conclusions about the classifier behavior, not dependent on the data set collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - A perspective from a Research Paper\n",
    "***\n",
    "**Key Findings:**\n",
    "\n",
    "* The classifiers most likely to be the bests are the random forest (RF) versions, the best of which achieves 94.1% of the maximum accuracy overcoming 90% in the 84.3% (102 out of 121) of the data sets.\n",
    "* The SVM with Gaussian kernel (implemented in C using LibSVM) achieves 92.3% of the maximum accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - A perspective from a Research Paper\n",
    "***\n",
    "A few models are clearly better than the remaining ones:\n",
    "* Random forest\n",
    "* SVM with Gaussian and polynomial kernels\n",
    "* C5.0 decision tree\n",
    "* avNNet (the multi-layer perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - A perspective from a Research Paper\n",
    "***\n",
    "**Paper Summary**\n",
    "\n",
    "* The random forest was found to be clearly the best family of classifiers (3 out of 5 bests classifiers are RF), followed by SVM (4 classifiers in the top-10), neural networks and boosting ensembles (5 and 3 members in the top-20, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - Some practical Tips\n",
    "***\n",
    "So far we have learnt about a bunch of algorithms. We have learnt about 2 families of algorithm\n",
    "    * Linear Models\n",
    "    * Ensemble Models\n",
    "\n",
    "The question is then which algorithm to use and when? Let’s have a look at some quick ideas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - Some practical Tips\n",
    "***\n",
    "Penalized linear regression methods have the advantage that they train very quickly. That helps us for 2 reasons\n",
    "* Training times on large data sets can extend to hours, days, or even weeks.\n",
    "* Long training times can stall development and deployment on large problems.\n",
    "Training usually needs to be done several times before a deployable solution is arrived at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - Some practical Tips\n",
    "***\n",
    "* Hence, rapid training time for penalized linear methods makes them useful for the obvious reason that shorter is better. \n",
    "* However, Depending on the problem, these methods may suffer some performance disadvantages relative to ensemble methods.\n",
    "* Therefore, penalized linear methods can be a useful first step in your development process even in the circumstance where they yield inferior performance to ensemble methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - Some practical Tips\n",
    "***\n",
    "* Besides enjoying a training time advantage, penalized linear methods generate predictions much faster than ensemble methods. \n",
    "* Generating a prediction involves using the trained model. The trained model for penalized linear regression is simply a list of real numbers—one for each feature being used to make the predictions. \n",
    "* The number of floating‐point operations involved is the number of variables being used to make predictions. \n",
    "* For highly time‐sensitive predictions such as high‐speed trading or Internet ad insertions, computation time makes the difference between making money and losing money. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - Some practical Tips\n",
    "***\n",
    "* On the other hand ensemble methods bring to the table the ability to work with nonlinear data\n",
    "* We can also easily control the complexity of ensemble models by tuning the hyperparameters\n",
    "* Also, ensemble methods come with the ability to tell apart important features from relatively redundant ones. Which is one of the huge advantages of ensemble methdos\n",
    "* Hence, ensemble methods could be used as the final predictors after feature engineering and feature selection has been carried out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - Some practical Tips\n",
    "***\n",
    "![](../images/image34.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Which Algorithm to Use? - Some practical Tips\n",
    "***\n",
    "![](../images/image35.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InClass Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit Delinquency Prediction\n",
    "\n",
    "\n",
    "### Problem statement\n",
    "\n",
    "Delinquency describes something or someone who fails to accomplish that which is required by law, duty, or contractual agreement, such as the failure to make a required payment or perform a particular action.\n",
    "\n",
    "Credit scoring algorithms, which makes a guess at the probability of default, are the method banks use to determine whether or not a loan should be granted. This use-case requires learners to improve on the state of the art in credit scoring, by predicting the probability that somebody will experience financial delinquency in the next two years.\n",
    "\n",
    "### Dataset description\n",
    "The dataset consists of 150000 records and 11 features. Below are the 11 features and their descriptions.\n",
    "\n",
    "|Feature|Description|\n",
    "|-----|-----|\n",
    "|SeriousDlqin2yrs|Person experienced 90 days past due delinquency or worse|\n",
    "|RevolvingUtilizationOfUnsecuredLines| Total balance on credit cards and personal lines of credit|\n",
    "|age| Age of borrower in years|\n",
    "|NumberOfTime30-59DaysPastDueNotWorse| Number of times borrower has been 30-59 days past due but no worse in the last 2 years|\n",
    "|DebtRatio| Monthly debt payments, alimony,living costs divided by monthy gross income|\n",
    "|MonthlyIncome|Monthly Income|\n",
    "|NumberOfOpenCreditLinesAndLoans| Number of Open loans (installment like car loan or mortgage) and Lines of credit|\n",
    "|NumberOfTimes90DaysLate|Number of times borrower has been 90 days or more past due|\n",
    "|NumberRealEstateLoansOrLines| Number of mortgage and real estate loans including home equity lines of credit|\n",
    "|NumberOfTime60-89DaysPastDueNotWorse| Number of times borrower has been 60-89 days past due but no worse in the last 2 years|\n",
    "|NumberOfDependents|Number of dependents in family excluding themselves|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from pylab import rcParams\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix,classification_report\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 :Load the data and get an overview of the data using `.describe()` and `.info()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/fin_dataset.csv',index_col=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../images/Recap.png\" alt=\"Recap\" style=\"width: 100px;float:left; margin-right:15px\"/>\n",
    "\n",
    "<br />\n",
    "\n",
    "# In-session Recap Time\n",
    "***\n",
    "* Imbalanced Data\n",
    "* Resampling Techniques\n",
    "* Undersampling & Oversampling\n",
    "* Algorithmic Approach\n",
    "* Dealing with smaller data sets\n",
    "* Which Algorithm to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are null values in the variables `NumberOfDependents` and `MonthlyIncome`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 : Check for the skewness in the variables in `NumberOfDependents`  and `MonthlyIncome` by plotting a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NumberOfDependents'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MonthlyIncome'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 :There is skewness in the feature `NumberOfDependents`. So let's replace the null values in this feature with the median and let's do the same for the feature `MonthlyIncome`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NumberOfDependents']  = df['NumberOfDependents'].fillna(df['NumberOfDependents'].median())\n",
    "\n",
    "df['MonthlyIncome'].fillna(df['MonthlyIncome'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Check for the distribution of the target variable using a `countplot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['SeriousDlqin2yrs'].value_counts()/df['SeriousDlqin2yrs'].value_counts().sum())\n",
    "\n",
    "sns.countplot(df['SeriousDlqin2yrs'],data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is heavy imbalance in the target variable. We will deal with this imbalance using different techniques below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 : Seperate the predictors and the target and split the data into training set and testing set. Keep the `test_size = 0.2` and the `random_state=42` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'SeriousDlqin2yrs'\n",
    "\n",
    "X = df.loc[:,df.columns!=target]\n",
    "Y = df.loc[:,df.columns==target]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 : For a better method of inference, let's check for the correlation between different features by plotting a heatmap. The basic rule of feature selection is that we need to select features which are highly correlated to the dependent variable and also not highly correlated with each other as they show the same trend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = X_train.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(15,13))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(250, 15, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5},annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 : We can see that the features `NumberOfTime60-89DaysPastDueNotWorse` is highly correlated along with the features `NumberOfTime30-59DaysPastDueNotWorse` and `NumberOfTimes90DaysLate`. So let's drop the features `NumberOfTime60-89DaysPastDueNotWorse` and `NumberOfTime30-59DaysPastDueNotWorse` from the train as well as the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['NumberOfTime30-59DaysPastDueNotWorse','NumberOfTime60-89DaysPastDueNotWorse'],1,inplace=True)\n",
    "X_test.drop(['NumberOfTime30-59DaysPastDueNotWorse','NumberOfTime60-89DaysPastDueNotWorse'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 : Fit a vanilla Logistic Regression model on the training set and predict on the test set and plot the confusion matrix, accuracy, precision, recall and F1_score for the predicted model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X_train, Y_train)\n",
    "\n",
    "Y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \" , accuracy_score(Y_test, Y_test_pred))\n",
    "print(\"Precision = \" ,precision_score(Y_test, Y_test_pred))\n",
    "print(\"Recall = \" ,recall_score(Y_test, Y_test_pred))\n",
    "print(\"F1 Score = \" ,f1_score(Y_test, Y_test_pred))\n",
    "\n",
    "pd.crosstab(Y_test_pred, Y_test[target], rownames=['Predicted'], colnames=['Actual'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The recall is low and this is because from the matrix above, we can see that the False Negatives are too many in the data. This was supposed to happen because since the target is highly imbalanced with lesser number of 1s, our model has learnt to predict only 0s most of the times. But as per our problem, we are more concerned with the occurence of a delinquency i.e with the prediction of 1s and not 0s. Hence we have to treat this class imbalance first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 : Set the parameter `class_weight=balanced` inside Logistic Regression and check for the metrics calculated above and also the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight='balanced').fit(X_train, Y_train)\n",
    "\n",
    "Y_test_pred_balanced = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy = \" , accuracy_score(Y_test, Y_test_pred_balanced))\n",
    "print(\"Precision = \" ,precision_score(Y_test, Y_test_pred_balanced))\n",
    "print(\"Recall = \" ,recall_score(Y_test, Y_test_pred_balanced))\n",
    "print(\"F1 Score = \" ,f1_score(Y_test, Y_test_pred_balanced))\n",
    "\n",
    "pd.crosstab(Y_test_pred_balanced, Y_test[target], rownames=['Predicted'], colnames=['Actual'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see that the recall has increased from ~1.4% to ~63% by setting the `class_weight`, since the False Negatives have also reduced, but the Precision seems to have reduced. This is a trade-off, we have to accept. \n",
    "\n",
    "### By setting the class weights we got a decent recall score. But this may not be the case all the times. In such cases, will have to use other resampling methods like \n",
    "- Random Oversampling\n",
    "- Random Undersampling\n",
    "- Tomek Undersampling\n",
    "- SMOTE \n",
    "\n",
    "### NOTE : All types of Undersampling and Oversampling techniques are always performed on the train data and not on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10 : Perform Random Undersampling on the train data and then fit a Logistic regression model on this undersampled data and then predict on the test data and calculate the precision, recall, accuracy, f1-score and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#Code starts here\n",
    "\n",
    "# Create random under sampler object\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "\n",
    "#Undersampling the train data\n",
    "X_sample_1, y_sample_1 =  rus.fit_sample(X_train, Y_train)\n",
    "\n",
    "\n",
    "#Initiating a logistic regression model\n",
    "model_rus = LogisticRegression()\n",
    "\n",
    "#Fitting the model with sampled data\n",
    "model_rus.fit(X_sample_1, y_sample_1)\n",
    "\n",
    "#Making prediction of test values\n",
    "Y_pred=model_rus.predict(X_test)\n",
    "\n",
    "# Calculating the necessary metrics\n",
    "print(\"Accuracy = \" , accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision = \" ,precision_score(Y_test, Y_pred))\n",
    "print(\"Recall = \" ,recall_score(Y_test, Y_pred))\n",
    "print(\"F1 Score = \" ,f1_score(Y_test, Y_pred))\n",
    "\n",
    "#Finding the confusion matrix\n",
    "pd.crosstab(Y_pred, Y_test[target], rownames=['Predicted'], colnames=['Actual'])\n",
    "\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So Random Undersampling gives a slightly better recall than just setting class_weights as balanced. Let's now see how another undersampling method called Tomek Undersampling performs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11 : Perform Tomek Undersampling on the train data and then fit a Logistic regression model on this undersampled data and then predict on the test data and calculate the precision, recall, accuracy, f1-score and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import package\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "#Code starts here\n",
    "\n",
    "#Initialising Tomek Links object\n",
    "tl = TomekLinks()\n",
    "\n",
    "#Undersamlpling the train data\n",
    "X_sample4, y_sample4 = tl.fit_sample(X_train, Y_train)\n",
    "\n",
    "# Plot the distribution of the target using a countplot\n",
    "sns.countplot(y_sample4)\n",
    "\n",
    "#Initialising the logistic regression model\n",
    "model_tl = LogisticRegression()\n",
    "\n",
    "#Fitting the model with sampled data\n",
    "model_tl.fit(X_sample4, y_sample4)\n",
    "\n",
    "#Making the predictions with test data\n",
    "Y_pred_tomek=model_tl.predict(X_test)\n",
    "\n",
    "# Calculating the necessary metrics\n",
    "print(\"Accuracy = \" , accuracy_score(Y_test, Y_pred_tomek))\n",
    "print(\"Precision = \" ,precision_score(Y_test, Y_pred_tomek))\n",
    "print(\"Recall = \" ,recall_score(Y_test, Y_pred_tomek))\n",
    "print(\"F1 Score = \" ,f1_score(Y_test, Y_pred_tomek))\n",
    "\n",
    "#Finding the confusion matrix\n",
    "pd.crosstab(Y_pred_tomek,Y_test[target],rownames=['Predicted'], colnames=['Actual'])\n",
    "\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tomek Undersampling doesn't seem a good fit for data. There is hardly any increase in recall compared to the vanilla model. Undersampling techniques, even if they provide an increase in the metric of choice, are not favoured since you tend to lose some information when you undersample the majority class of the target. Hence in most cases, what we prefer to perform are Oversampling techniques like Random Oversampling and SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12 : Perform Random Oversampling on the train data and then fit a Logistic regression model on this undersampled data and then predict on the test data and calculate the precision, recall, accuracy, f1-score and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Code starts here\n",
    "\n",
    "#Initialise the random over sampler object\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "\n",
    "#Sample the train data using random over sampling method\n",
    "X_sample_2, y_sample_2 = ros.fit_sample(X_train, Y_train)\n",
    "\n",
    "# Using a countplot \n",
    "sns.countplot(y_sample_2)\n",
    "\n",
    "#Initialising a logsitic regression model\n",
    "model_ros = LogisticRegression()\n",
    "\n",
    "#Fitting the model with train data\n",
    "model_ros.fit(X_sample_2, y_sample_2)\n",
    "\n",
    "#Making predictions of the train data\n",
    "Y_pred=model_ros.predict(X_test)\n",
    "\n",
    "# Calculating the necessary metrics\n",
    "print(\"Accuracy = \" , accuracy_score(Y_test, Y_pred))\n",
    "print(\"Precision = \" ,precision_score(Y_test, Y_pred))\n",
    "print(\"Recall = \" ,recall_score(Y_test, Y_pred))\n",
    "print(\"F1 Score = \" ,f1_score(Y_test, Y_pred))\n",
    "\n",
    "#Finding the confusion matrix \n",
    "pd.crosstab(Y_pred, Y_test[target], rownames=['Predicted'], colnames=['Actual'])\n",
    "\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So as you can observe from the above plot, oversampling has brought an equal balance in the distribution of classes in the target variable. Also the recall is much better compared to the vanilla model and Tomek undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 13 : Perform SMOTE on the train data and then fit a Logistic regression model on this undersampled data and then predict on the test data and calculate the precision, recall, accuracy, f1-score and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "#Code starts here\n",
    "\n",
    "#Initialising a SMOTE object\n",
    "smote = SMOTE(random_state=12,ratio=1.0)\n",
    "\n",
    "#Sampling the data using SMOTE\n",
    "X_sample_3, y_sample_3 = smote.fit_sample(X_train, Y_train)\n",
    "\n",
    "# Using a countplot plot the distribution of y_sample_3\n",
    "sns.countplot(y_sample_3)\n",
    "\n",
    "#Initialising Logistic Regression model\n",
    "model_smote = LogisticRegression()\n",
    "\n",
    "#Fitting the model on train data\n",
    "model_smote.fit(X_sample_3, y_sample_3)\n",
    "\n",
    "#Making predictions on test data\n",
    "Y_pred=model_smote.predict(X_test)\n",
    "\n",
    "#Finding the accuracy score \n",
    "accuracy_smote=model_smote.score(X_test,Y_test)\n",
    "print(\"Accuracy:\",accuracy_smote)       \n",
    "\n",
    "\n",
    "#Finding the recall score\n",
    "recall_smote=recall_score(Y_test, Y_pred)\n",
    "print (\"recall:\",recall_smote)\n",
    "\n",
    "#Finding the precision score\n",
    "precision_smote=precision_score(Y_test, Y_pred)\n",
    "print (\"precision:\",precision_smote)\n",
    "\n",
    "#Finding the f1 score\n",
    "f1_smote=f1_score(Y_test, Y_pred)\n",
    "print (\"f1_score:\", f1_smote)\n",
    "\n",
    "#Finding the confusion matrix\n",
    "pd.crosstab(Y_pred,Y_test[target], rownames=['Predicted'], colnames=['Actual'])\n",
    "#Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE performs on par with Random Oversampling giving almost the same recall ! "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
